# ğŸ™ï¸ Emotion Detection from Speech using Deep Learning

Welcome to my deep learning project where machines **learn to feel** â€” at least from sound! This is an end-to-end **Speech Emotion Recognition (SER)** system that processes raw `.wav` audio and identifies emotions like happiness, anger, sadness, and more.

---

## ğŸ¯ Goal

To design a fully functional pipeline that:
- Extracts emotional cues from human voice using signal processing
- Classifies them using a custom deep learning model
- Offers an easy-to-use web interface built with Streamlit

Whether itâ€™s a calm podcast or a dramatic song â€” this system picks up on the emotional tone.

---

## ğŸ’¡ What It Does

- ğŸµ Processes audio input (speech or song)
- ğŸ› Extracts features like MFCC, ZCR, RMSE
- ğŸ”„ Applies audio augmentation techniques
- ğŸ§  Runs inference using a 1D CNN
- ğŸŒ Serves real-time predictions via a Streamlit app

---

## ğŸ“¦ Dataset

This project uses the **RAVDESS** dataset â€” a well-known benchmark for emotion classification tasks involving both speech and song recordings.

> ğŸ§ [Download Dataset](https://zenodo.org/records/1188976#.XCx-tc9KhQI)

### Dataset Stats

| Emotion   | Samples |
|-----------|---------|
| Calm      | 376     |
| Happy     | 376     |
| Sad       | 376     |
| Angry     | 376     |
| Fearful   | 376     |
| Disgust   | 192     |
| Surprised | 192     |
| Neutral   | 188     |

---

## âš™ï¸ How It Works

### ğŸ”Š Feature Engineering
- **Sample Rate**: 22050 Hz
- **Windowing**: Frame = 2048, Hop = 512
- **Extracted Features**:
  - 13-dimensional MFCC
  - Zero Crossing Rate
  - Root Mean Square Energy  
- **Final Feature Vector**: Size = 2376

### ğŸ” Audio Augmentation
To make the model robust to variations, we use:
- Time Stretching
- Pitch Shifting
- Background Noise
- Speed Variation
- Random Audio Shifts

### ğŸ§± Model Design

A **custom 1D CNN** was trained with:
- 5 stacked Conv1D blocks + MaxPooling + BatchNorm
- Dropout layers to reduce overfitting
- Dense layers topped with softmax for 8-class output

> ğŸ“Š Parameters: ~7.2 million

---

## ğŸ§ª Training Configuration

- Optimizer: Adam
- Loss: Categorical Crossentropy
- Epochs: 40
- Batch Size: 64
- Dynamic Learning Rate: `ReduceLROnPlateau`

---

## ğŸ“Š Performance

| Metric        | Score     |
|---------------|-----------|
| Test Accuracy | 93.93%    |
| Macro F1      | 93.86%    |
| Micro F1      | 93.93%    |
| Weighted F1   | 93.94%    |

---

## ğŸŒ Web App Features (Streamlit)

The interactive app lets users:

- ğŸ“ Upload one or many `.wav` files
- ğŸ”Š Listen to each audio clip
- ğŸ“ˆ View prediction probabilities (bar/pie charts)
- ğŸ“‰ See audio waveforms + distributions
- ğŸ“¥ Export predictions to CSV

Live features:
- ğŸ”„ Lazy model loading
- ğŸ§  Fast inference pipeline
- ğŸ¯ Emotion distribution insights

---

## ğŸ—‚ï¸ Project Layout

